{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5a8e7fb",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49ae46f",
   "metadata": {},
   "source": [
    "## 0.1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6a5100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# preprocessing\n",
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler, StringIndexer\n",
    "from pyspark.sql.functions import col, count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0db8cc",
   "metadata": {},
   "source": [
    "## 0.2. Data acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17f92a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/08 16:39:35 WARN Utils: Your hostname, irish resolves to a loopback address: 127.0.1.1; using 192.168.0.17 instead (on interface enp3s0)\n",
      "22/06/08 16:39:35 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark-3.2.1-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/06/08 16:39:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/06/08 16:39:35 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n"
     ]
    }
   ],
   "source": [
    "MAX_MEMORY = '6g'\n",
    "\n",
    "# instantiate spark session object\n",
    "spark = SparkSession.builder \\\n",
    "                    .master('local[*]') \\\n",
    "                    .config('spark.local.dir', '/tmp') \\\n",
    "                    .config('spark.submit.deployMode', 'client') \\\n",
    "                    .config('spark.executor.instances', '16') \\\n",
    "                    .config('spark.driver.memory', MAX_MEMORY) \\\n",
    "                    .config('spark.executor.memory', MAX_MEMORY) \\\n",
    "                    .config('spark.executor.memoryOverhead', MAX_MEMORY) \\\n",
    "                    .config('spark.sql.debug.maxToStringFields', '100') \\\n",
    "                    .appName('airbnb-first-booking-prediction') \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e2cbb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# read checkpoint dataset\n",
    "df = spark.read.parquet('../data/interim/processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55703377",
   "metadata": {},
   "source": [
    "# 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394d117e",
   "metadata": {},
   "source": [
    "## 1.1. Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bf0f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train (80%) and validation (20%)\n",
    "train, val = df.randomSplit([0.8, 0.2], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "424023ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "X_train = train.drop('country_destination')\n",
    "X_val = val.drop('country_destination')\n",
    "\n",
    "# labels\n",
    "y_train = train.select('country_destination')\n",
    "y_val = val.select('country_destination')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0eabde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define categorical and numerical columns\n",
    "cat_cols = [col for (col, dtype) in train.dtypes if dtype == 'string']\n",
    "num_cols = list(set(train.columns) - set(cat_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598f2750",
   "metadata": {},
   "source": [
    "## 1.2. Rescale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d83ea1",
   "metadata": {},
   "source": [
    "### Min max scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be0287c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate vector assembler\n",
    "va_num = VectorAssembler(inputCols=['secs_elapsed'], outputCol='secs_elapsed_vect')\n",
    "\n",
    "# transform\n",
    "X_train_vect = va_num.transform(X_train)\n",
    "X_val_vect = va_num.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0391d2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# instantiate and save the scaler\n",
    "mms = MinMaxScaler(inputCol='secs_elapsed_vect', outputCol='secs_elapsed_scaled').fit(X_train_vect)\n",
    "mms.write().overwrite().save('../parameters/mms')\n",
    "\n",
    "# rescale\n",
    "X_train = mms.transform(X_train_vect).drop('secs_elapsed', 'secs_elapsed_vect')\n",
    "X_val = mms.transform(X_val_vect).drop('secs_elapsed', 'secs_elapsed_vect')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d317c08",
   "metadata": {},
   "source": [
    "## 1.3. Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bb8880",
   "metadata": {},
   "source": [
    "### Label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdd49a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# columns to enconde\n",
    "label_cols = ['gender', 'first_device_type', 'signup_method', 'signup_app']\n",
    "\n",
    "for col in label_cols:\n",
    "    # instantiate and save each caler\n",
    "    si = StringIndexer(inputCol=col, outputCol=col + '_encoded').fit(X_train)\n",
    "    si.write().overwrite().save('../parameters/si_' + col)\n",
    "    \n",
    "    # encode\n",
    "    X_train = si.transform(X_train).drop(col)\n",
    "    X_val = si.transform(X_val).drop(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c79c4b",
   "metadata": {},
   "source": [
    "### Frequency encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22c52a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "X_train_length = X_train.count()\n",
    "X_val_length = X_val.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df10f58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 144:================================>                      (10 + 7) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|language|           frequency|\n",
      "+--------+--------------------+\n",
      "|      en|  0.9634236100927227|\n",
      "|      pl|1.541754790173585...|\n",
      "|      pt|0.001579392565340...|\n",
      "|      ko|0.006378627096633176|\n",
      "|      cs|1.025977871218588...|\n",
      "|      tr|1.750853541101286...|\n",
      "|      de|0.002505281834448434|\n",
      "|      is|1.505511006679450...|\n",
      "|      es|0.003971761074288047|\n",
      "|      el|1.781521357904016...|\n",
      "|      it|0.001649649745652...|\n",
      "|      sv|5.634514341665128E-4|\n",
      "|      nl|3.515646998931087E-4|\n",
      "|      hu|2.899502679530793...|\n",
      "|      ca|9.757941709959402E-6|\n",
      "|      ru|0.001656898502351...|\n",
      "|      th|7.025718031170769E-5|\n",
      "|      no|3.038901846815928E-5|\n",
      "|      zh|0.011316703198541772|\n",
      "|      fr|0.004262547737244837|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 144:===================================================>   (16 + 1) / 17]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "X_train.groupBy('language') \\\n",
    "       .agg((count('language') / X_train_length).alias('frequency')) \\\n",
    "       .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fa0e4cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to encode\n",
    "frequency_cols = ['signup_flow', 'language', 'affiliate_channel', 'affiliate_provider',\n",
    "                  'first_affiliate_tracked', 'first_device_type', 'first_browser',\n",
    "                  'action','action_type', 'action_detail', 'device_type']\n",
    "\n",
    "for col in frequency_cols:\n",
    "    # instantiate and save each caler\n",
    "    si = StringIndexer(inputCol=col, outputCol=col + '_encoded').fit(X_train)\n",
    "    si.write().overwrite().save('../parameters/si_' + col)\n",
    "    \n",
    "    # encode\n",
    "    X_train = si.transform(X_train).drop(frequency_cols)\n",
    "    X_val = si.transform(X_val).drop(frequency_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f553bd75",
   "metadata": {},
   "source": [
    "## 1.4. Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68ed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_cols = ['week_of_year_account_created', 'timestamp_first_active_week_of_year',\n",
    "                  'day_of_week_first_booking', 'timestamp_first_active_day_of_week',\n",
    "                  'week_of_year_first_booking', 'day_of_week_account_created', 'month_account_created',\n",
    "                  'day_account_created', 'timestamp_first_active_month', 'timestamp_first_active_day',\n",
    "                  'month_first_booking', 'day_first_booking']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf2f0e7",
   "metadata": {},
   "source": [
    "# 2. Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaece4e",
   "metadata": {},
   "source": [
    "## 2.1. Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5067e65f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0527c91",
   "metadata": {},
   "source": [
    "## 2.2. Select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e847a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
